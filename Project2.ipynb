{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete data likelihood:\n",
    "\n",
    "\\begin{aligned}\n",
    "p(\\mathbf{Z}, \\mathbf{X}, \\mathbf{H}, \\mathbf{Y} | \\Theta) &=\\prod_{i=1}^{N} P\\left(\\mathbf{z}_{i}\\right) p\\left(\\mathbf{x}_{i} | \\mathbf{z}_{i}\\right) p\\left(\\mathbf{h}_{i} | \\mathbf{x}_{i}\\right) p\\left(\\mathbf{y}_{i} | \\mathbf{h}_{i}, \\mathbf{x}_{i}\\right) \\\\\n",
    "&=\\prod_{i=1}^{N}\\left[p\\left(\\mathbf{z}_{i}\\right) \\prod_{j=1}^{p} p\\left(x_{i j} | \\mathbf{z}_{i}\\right) p\\left(h_{i j} | x_{i j}\\right) p\\left(y_{i j} | x_{i j}, h_{i j}\\right)\\right] \\\\\n",
    "&=\\prod_{i=1}^{N}\\left[p\\left(\\mathbf{z}_{i}\\right) \\prod_{j: y_{i j}=0} p\\left(x_{i j} | \\mathbf{z}_{i}\\right) p\\left(h_{i j}=1 | x_{i j}\\right) \\prod_{j: y_{i j} \\neq 0} p\\left(x_{i j}=y_{i j} | \\mathbf{z}_{i}\\right) p\\left(h_{i j}=0 | x_{i j}\\right)\\right]\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete data log likelihood:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\ln p(\\mathbf{Z}, \\mathbf{X}, \\mathbf{H}, \\mathbf{Y} | \\Theta) & \\propto-\\frac{1}{2} \\sum_{i=1}^{N} \\mathbf{z}_{i}^{T} \\mathbf{z}_{i} \\\\\n",
    "&+\\sum_{i=1}^{N}\\left[\\sum_{j: y_{i j}=0}\\left\\{-\\frac{\\left(x_{i j}-\\left(\\mathbf{A} \\mathbf{z}_{i j}+\\boldsymbol{\\mu}\\right)\\right)^{2}}{2 \\sigma_{j}^{2}}- \\ln \\sigma_{j}-\\lambda x_{i j}^{2}\\right\\}\\right] \\\\\n",
    "&+\\sum_{i=1}^{N}\\left[\\sum_{j: y_{i j}=0}\\left\\{-\\frac{\\left(y_{i j}-\\left(\\mathbf{A} \\mathbf{z}_{i j}+\\boldsymbol{\\mu}\\right)\\right)^{2}}{2 \\sigma_{j}^{2}}- \\ln \\sigma_{j}+\\ln \\left(1-\\exp \\left(-\\lambda y_{i j}^{2}\\right)\\right)\\right\\}\\right]\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(z_i,x_{i0}|y_i)$ with mean\n",
    "\n",
    "$$\n",
    "\\left(\\boldsymbol{\\Sigma}_{c}^{-1}+2 \\lambda \\mathbf{I}_{x}\\right)^{-1}\n",
    "\\boldsymbol{\\Sigma}_{c}^{-1} \\boldsymbol{\\mu}_{c}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and variance\n",
    "\n",
    "$$\\left(\\boldsymbol{\\Sigma}_{c}^{-1}+2 \\lambda \\mathbf{I}_{x}\\right)^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M-step:\n",
    "A, $\\mu$, W have analytic solution while $\\lambda$ needs numerical method to approach\n",
    "\n",
    "$$\\mu_{j}=\\frac{1}{N}\\left[\\sum_{i: y_{i j}=0}\\left(E\\left[x_{i j}\\right]-\\sum_{k=1}^{K} a_{j k} E\\left[z_{i k}\\right]\\right)+\\sum_{i: y_{i j}>0}\\left(y_{i j}-\\sum_{k=1}^{K} a_{j k} E\\left[z_{i k}\\right]\\right)\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "{a_{j k}=\\frac{1}{\\sum_{i=1}^{N} E\\left[z_{i k}^{2}\\right]}\\left[\\sum_{i: y_{i j}=0}\\left(E\\left[x_{i j} z_{i k}\\right]-\\mu_{j} E\\left[z_{i k}\\right]-\\sum_{k^{\\prime} \\neq k} a_{j k^{\\prime}} E\\left[z_{i k} z_{i k^{\\prime}}\\right]\\right)+\\right.}\\\\{\\left.\\sum_{i: y_{i j}>0}\\left(Y_{i j} E\\left[z_{i k}\\right]-\\mu_{j} E\\left[z_{i k}\\right]-\\sum_{k^{\\prime} \\neq k} a_{j k^{\\prime}} E\\left[z_{i k} z_{i k^{\\prime}}\\right]\\right)\\right]}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma^{2}=\\frac{1}{N D} \\sum_{j}\\left(\\sum_{i: y_{i j}=0}\\left(E\\left[x_{i j}^{2}\\right]-2 E\\left[x_{i j} m_{i j}\\right]+E\\left[m_{i j}^{2}\\right]\\right)+\\sum_{i: y_{i j}>0}\\left(y_{i j}^{2}-2 y_{i j} E\\left[m_{i j}\\right]+E\\left[m_{i j}^{2}\\right]\\right)\\right)\n",
    "$$\n",
    "\n",
    "The derivation is so challenging that I refer to the supplementary information of paper, and I go through the whole logic and all equations in my implementation. There are some mistakes in the supplementary information and some obvious ones recognized by me is being revised in my implementation, while there might be others that I have not noticed. Also, there are many details that I have not thought about so that there are still distance between my implementation and the official one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy as dcpy\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "eps = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick print and check the shape of matrix to debug\n",
    "def prt(str, X):\n",
    "    print(str, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(Y, A, MU, W, _lambda):\n",
    "    omega = (Y > eps).astype(int)\n",
    "    N, D = Y.shape\n",
    "    K = A.shape[1]\n",
    "    \n",
    "    #Initialization: an easy way to determine the dimension is the different indexs in one term\n",
    "    EZ = np.zeros([N, K])\n",
    "    EX = np.zeros([N, D])\n",
    "    EX2 = np.zeros([N, D])\n",
    "    EXZ = np.zeros([N, D, K])\n",
    "    EZZT = np.zeros([N, K, K])\n",
    "    \n",
    "    # prior distribution p(zi, xi) is a multivariate normal\n",
    "    prior_dim = K + D\n",
    "    prior_mean = np.zeros(prior_dim)\n",
    "    prior_mean[K: prior_dim] = dcpy(MU)\n",
    "    prior_covar = np.zeros((prior_dim, prior_dim))\n",
    "    prior_covar[:K, :K] = np.identity(K)\n",
    "    prior_covar[K:, :K] = dcpy(A)\n",
    "    prior_covar[:K, K:] = dcpy(A.T)\n",
    "    prior_covar[K:, K:] = A @ A.T + W\n",
    "    for i in range(N):\n",
    "        # separate indexs into two parts by the corresponding value\n",
    "        zero_idx = np.squeeze(np.array(np.nonzero(1-omega[i])))\n",
    "        pos_idx = np.squeeze(np.array(np.nonzero(omega[i])))\n",
    "        # the return value of np.nonzero() is in the format of tuple, which needs transformation\n",
    "        #prt('pos_idx', pos_idx)\n",
    "        \n",
    "        # auxiliary variables for mu_c and sigma_c\n",
    "        mu_0 = prior_mean[zero_idx]\n",
    "        mu_p = prior_mean[pos_idx]\n",
    "        yi_p = Y[i][pos_idx]\n",
    "        \n",
    "        row_zero = prior_covar[zero_idx]\n",
    "        row_pos = prior_covar[pos_idx]\n",
    "        sigma_00 = row_zero[:, zero_idx]\n",
    "        sigma_0p = row_zero[:, pos_idx]\n",
    "        sigma_p0 = row_pos[:, zero_idx]\n",
    "        sigma_pp = row_pos[:, pos_idx]\n",
    "        \n",
    "        # calculate mu_c and sigma_c\n",
    "        mu_c = mu_0 + sigma_0p @ np.linalg.inv(sigma_pp) @ (yi_p - mu_p)\n",
    "        sigma_c = sigma_00 - sigma_0p @ np.linalg.inv(sigma_pp) @ sigma_p0\n",
    "        \n",
    "        # p(zi, xi0|yi) is also is a multivariate normal distribution\n",
    "        post_mean_XZ = np.linalg.inv( np.identity(len(zero_idx)) + 2*_lambda*sigma_c ) @ mu_c\n",
    "        post_covar_XZ = np.linalg.inv( np.linalg.inv(sigma_c) + 2*_lambda*np.identity(len(zero_idx)) )\n",
    "        \n",
    "        EZ[i, :] = post_mean_XZ[:K, 0]\n",
    "        EX[i, zero_idx] = post_mean_XZ[K:, 0]\n",
    "        EX2[i, zero_idx] = post_mean_XZ[K:, 0]**2 + np.diag(post_var[K:, K:])\n",
    "        EXZ[i, zero_idx, :] = post_mean_XZ[K:], post_mean_XZ[:K].T + post_covar_XZ[K:, :K]\n",
    "        EZZT[i, :, :] = post_mean_XZ[:K, :] @ post_mean_XZ[:K, :].T + post_covar_XZ[:K, :K]\n",
    "        \n",
    "        return EZ, EX, EX2, EXZ, EZZT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, Y, EX2):\n",
    "    y_squared = Y ** 2\n",
    "    Y_is_zero = np.abs(Y) < 1e-6\n",
    "    exp_Y_squared = np.exp(-x * y_squared)\n",
    "    log_exp_Y = np.nan_to_num(np.log(1 - exp_Y_squared))\n",
    "    exp_ratio = np.nan_to_num(exp_Y_squared / (1 - exp_Y_squared))\n",
    "    obj = sum(sum(Y_is_zero * (-EX2 * x) + (1 - Y_is_zero) * log_exp_Y))\n",
    "    grad = sum(sum(Y_is_zero * (-EX2) + (1 - Y_is_zero) * y_squared * exp_ratio))\n",
    "    \n",
    "    return obj, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(Y, A_old, MU_old, W_old, _lambda_old, EZ, EX, EX2, EXZ, EZZT, ):\n",
    "    omega = (Y > eps).astype(int)\n",
    "    N, D = Y.shape\n",
    "    K = A_old.shape[1]\n",
    "    \n",
    "    # A, MU, W have analytic solution while _lambda needs numerical method\n",
    "    \n",
    "    B = np.zeros((K+1, K+1)) # B: same for all j\n",
    "    for k1 in range(K):\n",
    "        for k2 in range(K):\n",
    "            # calculate K*K submatrix\n",
    "            B[k1][k2] = sum(EZZT[:, k1, k2])\n",
    "    B[K, :K] = EZ.sum(axis=0) # last row\n",
    "    B[:K, K] = EZ.sum(axis=0) # last column\n",
    "    B[K, K] = N # last component\n",
    "            \n",
    "    # all denominators are eliminated together for each line in B and c\n",
    "    \n",
    "    c = np.zeros((K+1, D)) \n",
    "    for k in range(K):\n",
    "        for j in range(D):\n",
    "            for i in range(N):\n",
    "                if omega[i][j]:\n",
    "                    c[k][j] = c[k][j] + Y[i][j] * EZ[i][k]\n",
    "                else:\n",
    "                    c[k][j] = c[k][j] + EXZ[i][j][k]\n",
    "    # try to get rid of bugs using elementwise operation\n",
    "    for j in range(D):\n",
    "        for i in range(N):\n",
    "            if Y[i][j]:\n",
    "                c[K][j] = c[K][j] + Y[i][j]\n",
    "            else:\n",
    "                c[K][j] = c[K][j] + EX[i][j]\n",
    "    \n",
    "    u = np.linalg.inv(B) @ c\n",
    "    A = u[:K, :].T\n",
    "    MU = np.atleast_2d(u[K, :]).T\n",
    "    \n",
    "    # m_ij = sigma_k A_jk*Z_jk +mu_j\n",
    "    EXM = np.zeros((N, D))\n",
    "    EM = np.zeros((N, D))\n",
    "    EM2 = np.zeros((N, D))\n",
    "    \n",
    "    A_product = np.tile(np.reshape(A, [1, D, K]), [K, 1, 1]) * (np.tile(np.reshape(A, [1, D, K]), [K, 1, 1]).T)\n",
    "    tiled_A = np.tile(np.resize(A, [1, D, K]), [N, 1, 1])\n",
    "    tiled_EZ = np.tile(np.resize(EZ, [N, 1, K]), [1, D, 1])\n",
    "    test_sum = (tiled_A * tiled_EZ).sum(axis=2)\n",
    "    tiled_mus = np.tile(MU.T, [N, 1])\n",
    "    \n",
    "    for i in range(N):\n",
    "        EXM[i, :] = A * EXZ[i].sum(axis=2) + MU * EX[i]\n",
    "        EM[i, :] = A @ EZ[i, :].T + MU.T\n",
    "        \n",
    "        EZZT_tiled = np.tile(np.reshape(EZZT[i, :, :], [K, 1, K]), [1, D, 1])\n",
    "        ezzt_sum = (EZZT_tiled * A_product).sum(axis=2).sum(axis=0)\n",
    "        EM2[i, :] = ezzt_sum + 2 * test_sum[i, :] * tiled_mus[i, :] + tiled_mus[i, :] ** 2\n",
    "    \n",
    "    W = ((1-omega) * (EX2 - 2*EXM + EM2) + omega * (Y**2 - 2*Y*EM + EM2)).sum(axis=0)\n",
    "    W = 1.0 * W / N / D\n",
    "    \n",
    "    coef = minimize(lambda x: func(x, Y, EX2), _lambda_old, jac=True, bounds=[[eps, np.inf]])\n",
    "    _lambda = coef.x[0]\n",
    "    \n",
    "    return A, MU, W, _lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_M(Y, K):\n",
    "    '''\n",
    "    Y: observed data, (N, D)\n",
    "    K: dimension of latent space, e.g., l = 10\n",
    "    '''\n",
    "    # Initialize parameter(A, MU, W, _lambda)\n",
    "    N, D = Y.shape\n",
    "    #FA = FactorAnalysis(K)\n",
    "    A = np.random.rand(D, K)\n",
    "    MU = np.random.rand(D)\n",
    "    W = np.random.rand(D, D)\n",
    "    _lambda = np.random.rand()\n",
    "    \n",
    "    it = 0\n",
    "    maxiter = 100\n",
    "    while it < maxiter:\n",
    "        it = it+1\n",
    "        \n",
    "        EZ, EZ2, EX, EX2, EZZT, EXZ = E_step(Y, A, MU, W, _lambda)\n",
    "        A, MU, W, _lambda = M_step(Y, A, MU, W, _lambda, EZ, EZ2, EX, EX2, EZZT, EXZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop rate: 0.578\n"
     ]
    }
   ],
   "source": [
    "# Simulation study(set up same as paper)\n",
    "N = 150\n",
    "K = 10\n",
    "D = 50\n",
    "sigma2 = 0.3\n",
    "_lambda = 0.1\n",
    "# parameter\n",
    "A = np.random.uniform(-0.5, 0.5, (D, K))\n",
    "MU = np.random.uniform(2.7, 3.3, D)\n",
    "W = np.random.uniform(0.9, 1.1, D) * sigma2\n",
    "#latent variable\n",
    "Z = np.random.normal(0, 1, (N, K))\n",
    "X = np.zeros((N, D))\n",
    "for i in range(N):\n",
    "    X[i, :] = np.random.normal(A @ Z[i, :] + MU, np.sqrt(W))\n",
    "P = np.exp(-_lambda * X**2)\n",
    "H = np.random.binomial(n=1, p=P, size = (N, D))\n",
    "Y = X * H\n",
    "print('Drop rate:', 1 - H.sum()/N/D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#E_M(Y, K) #bugs unfixed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
